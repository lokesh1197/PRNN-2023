{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ffc01bd-eb75-4f77-a22e-93b3861ed8c4",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bcc2464-43fb-47e7-98d7-289b92809c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "547e5a6d-ddf9-437d-8861-4d7bf8d6eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder = \"./data\"\n",
    "p1 = { \"testDir\": dataFolder + \"/p1_test.csv\", \"trainDir\": dataFolder + \"/p1_train.csv\" }\n",
    "p2 = { \"testDir\": dataFolder + \"/p2_test.csv\", \"trainDir\": dataFolder + \"/p2_train.csv\" }\n",
    "p3 = { \"testDir\": dataFolder + \"/p3_test.csv\", \"trainDir\": dataFolder + \"/p3_train.csv\" }\n",
    "\n",
    "p1[\"test\"] = np.genfromtxt(p1[\"testDir\"], delimiter=',')\n",
    "p1[\"train\"] = np.genfromtxt(p1[\"trainDir\"], delimiter=',')\n",
    "p2[\"test\"] = np.genfromtxt(p2[\"testDir\"], delimiter=',')\n",
    "p2[\"train\"] = np.genfromtxt(p2[\"trainDir\"], delimiter=',')\n",
    "p3[\"test\"] = np.genfromtxt(p3[\"testDir\"], delimiter=',')\n",
    "p3[\"train\"] = np.genfromtxt(p3[\"trainDir\"], delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c411608f-3337-476f-ae39-2c61e30896d0",
   "metadata": {},
   "source": [
    "# P1 (Regression Analysis)\n",
    "\n",
    "In this problem, the task is to predict the current health (as given by the target variable) of an organism given the measurements from two biological sensors measuring their bio-markers (negative indicates that it is lesser than the average case). \n",
    "\n",
    "With this data, you are expected to try our linear regression models on the  training data and report the following metrics on the test split: \n",
    "- Mean Squared Error, \n",
    "- Mean Absolute Error, \n",
    "- p-value out of significance test.\n",
    "\n",
    "**DATA:** `p1train/test.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "489c6de3-7ff2-4352-8460-277b06db2a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1[\"train\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "307cc580-dc85-44ec-8544-1c4c2392acfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean squared error\n",
    "def mse(X, Y, W):\n",
    "    return (1/2) * (X @ W - Y) @ (X @ W - Y)\n",
    "\n",
    "# Compute mean absolute error\n",
    "def mae(X, Y, W):\n",
    "    return np.sum(np.abs(X @ W - Y))\n",
    "\n",
    "# Split the training data into features matrix with bias and the result vector\n",
    "def splitData(data):\n",
    "    X = np.c_[np.ones(data.shape[0]), data.T[:2].T]\n",
    "    Y = data.T[-1].T\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "56b60d44-defc-4830-b0b2-537204d8ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = splitData(p1[\"train\"])\n",
    "\n",
    "# Initialise the parameters to be a null vector\n",
    "W = np.array([0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "43b8454d-b1c9-4707-b513-8e0c931c4521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3389272.628302881\n",
      "217168.26712067553\n"
     ]
    }
   ],
   "source": [
    "print(mse(X, Y, W))\n",
    "print(mae(X, Y, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aebea7f7-c05c-47e6-ac85-f7bec38bf958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (train-split):  25298.423078218584\n",
      "MAE (train-split):  17917.53209393991\n"
     ]
    }
   ],
   "source": [
    "W = np.linalg.pinv(X) @ Y\n",
    "\n",
    "print(\"MSE (train-split): \", mse(X, Y, W))\n",
    "print(\"MAE (train-split): \", mae(X, Y, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6ea0f16a-c690-494a-9ffd-1d23f0c1e188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) MSE:  12616.090009878131\n",
      "b) MAE:  8995.400265491306\n",
      "c) p-value -> sensor 1:  9.492378356739791e-30 , sensor 2:  3.0848891994991416e-26\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "X_test, Y_test = splitData(p1[\"test\"])\n",
    "\n",
    "print(\"a) MSE: \", mse(X_test, Y_test, W))\n",
    "print(\"b) MAE: \", mae(X_test, Y_test, W))\n",
    "print(\"c) p-value -> sensor 1: \", ttest_ind(X[:, 1], Y).pvalue, \", sensor 2: \", ttest_ind(X[:, 2], Y).pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da34880-85e7-4471-9ff1-2da09b1af936",
   "metadata": {},
   "source": [
    "# P2 (Regression Analysis)\n",
    "\n",
    "Here, you are expected to predict the lifespan of the above organism given the data from three sensors. In this case, the model is not linear.\n",
    "\n",
    "You are expected to try several (at least 3) non-linear regression models on the train split and report the following metrics on the test split.\n",
    "- Mean Squared Error\n",
    "- Mean Absolute Error\n",
    "- p-value out of significance test\n",
    "\n",
    "**DATA**: `p2train/test.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd4f2067-81af-46de-ac8d-c33fd6c65dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.50199562e+00, -8.53698298e+00,  3.42293467e+00,\n",
       "         1.19980220e+05],\n",
       "       [ 1.32838341e+00,  8.94357801e+00, -8.14530720e+00,\n",
       "         2.98902250e+04],\n",
       "       [ 1.61478186e-01, -7.92835138e+00,  1.62892423e+00,\n",
       "         3.24557940e+03],\n",
       "       ...,\n",
       "       [ 5.15542189e+00,  5.50082251e+00,  7.80498384e+00,\n",
       "         1.65778154e+05],\n",
       "       [ 7.41019691e+00, -3.09607941e+00,  4.39444446e+00,\n",
       "         2.12850414e+05],\n",
       "       [ 8.65839198e+00,  2.12902551e+00, -2.23757771e+00,\n",
       "         3.96440751e+05]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2337fbae-68a6-4b90-a8ac-27c8063205a9",
   "metadata": {},
   "source": [
    "# P3 (Multi-class classification)\n",
    "\n",
    "We have data from 10 sensors fitted in an industrial plant. There are five classes indicating which product is being produced. The task is to predict the product being produced by looking at the observation from these 10 sensors. \n",
    "\n",
    "Given this, you are expected to implement \n",
    "- Bayes’ classifiers with 0-1 loss assuming Normal, exponential, and GMMs (with diagonal co-variances) as class-conditional densities. For GMMs, code up the EM algorithm,\n",
    "- Linear classifier using the one-vs-rest approach\n",
    "- Multi-class Logistic regressor with gradient descent.\n",
    "\n",
    "The metrics to be computed are \n",
    "- Classification accuracy, \n",
    "- Confusion matrix,\n",
    "- Class-wise F1 score, \n",
    "- RoC curves for any pair of classes, and \n",
    "- likelihood curve for EM with different choices for the number of mixtures as hyper-parameters, \n",
    "- Emipiral risk on the train and test data while using logistic regressor.\n",
    "\n",
    "**DATA:** `p3train/test.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e444d8-c4ec-4633-90ec-be138198f4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.66524016, -1.44494482, -0.50279241, ..., -0.51264941,\n",
       "         1.14855255,  1.        ],\n",
       "       [ 2.77439505,  1.60670577,  0.55340908, ..., -0.3560387 ,\n",
       "         0.67794381,  1.        ],\n",
       "       [-0.62586937, -0.26507389,  0.70141731, ...,  0.10409147,\n",
       "        -0.98485438,  5.        ],\n",
       "       ...,\n",
       "       [-1.7652821 , -0.13820513, -2.05887396, ..., -0.16761556,\n",
       "         1.92810659,  5.        ],\n",
       "       [ 1.31672603,  0.29958778,  0.40964062, ..., -0.50250074,\n",
       "        -0.77139579,  2.        ],\n",
       "       [ 0.41895968,  1.06039492, -1.1435325 , ...,  1.16254537,\n",
       "         0.12443366,  4.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c4ffda-da5a-4cff-8bb9-7814723417d9",
   "metadata": {},
   "source": [
    "# P4 (Multi-class classification)\n",
    "\n",
    "In this problem, we consider an image dataset called Kannada-MNIST. This dataset contains images (60,000 images with 6000 per class) of digits from the south Indian language of Kannada. The task is to build a 10-class classifier for the digits. \n",
    "\n",
    "You are supposed to test the following classification schemes: \n",
    "- Naive Bayes’ with Normal as Class conditional\n",
    "- Logistic regressor with gradient descent\n",
    "- Multi-class Bayes’ classifier with GMMs with diagonal co-variances for class conditionals.\n",
    "\n",
    "Report the following metrics on the test data: \n",
    "- Classification accuracy\n",
    "- Confusion matrix\n",
    "- Class-wise F1 score\n",
    "- RoC curves for any pair of classes\n",
    "- likelihood curve for EM with different choices for the number of mixtures as hyper-parameters\n",
    "- Emipiral risk on the train and test data while using logistic regressor\n",
    "\n",
    "In this problem, first split the data into train and test parts with the following ratios of **20:80**, **30:70**, **50:50**, **70:30**, and **90:10**, and record your observations. Train the algorithms on the train part and evaluate over the test part.\n",
    "\n",
    "**DATA:** `images.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4326c625-75f0-4646-a3dd-52f5a6a34d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55265079-c87a-4aa6-a23d-865a1ad9f853",
   "metadata": {},
   "source": [
    "# P5 (Multi-class classification)\n",
    "\n",
    "In this part, the data from the previous problem is ’condensed’ (using PCA) to **10 dimensions**. Repeat the above experiment with all the models and metrics and record your observations.\n",
    "\n",
    "**DATA:** `KannadaMNISTPCA.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c87c0-d3a1-447e-8573-c76f0e6a5b79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
